Starting at Tue Jun 13 02:23:28 AM UTC 2023
Current working directory is /home/leonkl/cme-213/final_project
The master node of this job is: icmet04
Number of compute nodes: 1
Compute node names: icmet04
Using 4 tasks per node.
Number of CPUs on node: 4.
----------------


mpirun -np 1 ./main -d -g 1
Number of MPI processes         1
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-1-1.txt
Time for Parallel Training: 9.44765 seconds
Precision on validation set for parallel training =   0.9104999899864197
Precision on testing set for parallel training =   0.8920000195503235

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-1.mat
Loading from file ./cpu_output/seq_nn-b0-1.mat
Loading from file ./cpu_output/seq_nn-W1-1.mat
Loading from file ./cpu_output/seq_nn-b1-1.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-1-1.txt
Max norm of diff b/w seq and par: W[0]: 1.24679e-07, b[0]: 6.72605e-07
l2  norm of diff b/w seq and par: W[0]: 1.51362e-07, b[0]: 5.1166e-07
Max norm of diff b/w seq and par: W[1]: 1.62851e-07, b[1]: 9.71734e-07
l2  norm of diff b/w seq and par: W[1]: 1.91931e-07, b[1]: 9.79369e-07


mpirun -np 2 ./main -d -g 1
Number of MPI processes         2
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-2-1.txt
[icmet04:393055] *** An error occurred in MPI_Recv
[icmet04:393055] *** reported by process [2556428289,1]
[icmet04:393055] *** on communicator MPI_COMM_WORLD
[icmet04:393055] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393055] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393055] ***    and potentially your MPI job)
[warn] Epoll MOD(1) on fd 24 failed.  Old events were 6; read change was 0 (none); write change was 2 (del): Bad file descriptor
[warn] Epoll MOD(4) on fd 24 failed.  Old events were 6; read change was 2 (del); write change was 0 (none): Bad file descriptor


mpirun -np 3 ./main -d -g 1
Number of MPI processes         3
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-3-1.txt
[icmet04:393079] *** An error occurred in MPI_Recv
[icmet04:393079] *** reported by process [2555052033,2]
[icmet04:393079] *** on communicator MPI_COMM_WORLD
[icmet04:393079] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393079] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393079] ***    and potentially your MPI job)
[icmet04:393073] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[icmet04:393073] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages


mpirun -np 4 ./main -d -g 1
Number of MPI processes         4
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-4-1.txt
[icmet04:393104] *** An error occurred in MPI_Recv
[icmet04:393104] *** reported by process [2561736705,1]
[icmet04:393104] *** on communicator MPI_COMM_WORLD
[icmet04:393104] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393104] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393104] ***    and potentially your MPI job)
[icmet04:393099] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[icmet04:393099] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages
[warn] Epoll MOD(1) on fd 25 failed.  Old events were 6; read change was 0 (none); write change was 2 (del): Bad file descriptor
[warn] Epoll MOD(4) on fd 25 failed.  Old events were 6; read change was 2 (del); write change was 0 (none): Bad file descriptor
[warn] Epoll MOD(1) on fd 23 failed.  Old events were 6; read change was 0 (none); write change was 2 (del): Bad file descriptor
[warn] Epoll MOD(4) on fd 23 failed.  Old events were 6; read change was 2 (del); write change was 0 (none): Bad file descriptor


mpirun -np 1 ./main -d -g 2
Number of MPI processes         1
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-1-2.txt
Time for Parallel Training: 2.45947 seconds
Precision on validation set for parallel training =   0.8845000267028809
Precision on testing set for parallel training =   0.8647999763488770

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-2.mat
Loading from file ./cpu_output/seq_nn-b0-2.mat
Loading from file ./cpu_output/seq_nn-W1-2.mat
Loading from file ./cpu_output/seq_nn-b1-2.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-1-2.txt
Max norm of diff b/w seq and par: W[0]: 9.32387e-08, b[0]: 7.19345e-07
l2  norm of diff b/w seq and par: W[0]: 1.09187e-07, b[0]: 4.19014e-07
Max norm of diff b/w seq and par: W[1]: 1.27186e-07, b[1]: 6.3164e-07
l2  norm of diff b/w seq and par: W[1]: 1.55776e-07, b[1]: 4.95631e-07


mpirun -np 2 ./main -d -g 2
Number of MPI processes         2
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-2-2.txt
[icmet04:393149] *** An error occurred in MPI_Recv
[icmet04:393149] *** reported by process [2558656513,1]
[icmet04:393149] *** on communicator MPI_COMM_WORLD
[icmet04:393149] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393149] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393149] ***    and potentially your MPI job)


mpirun -np 3 ./main -d -g 2
Number of MPI processes         3
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-3-2.txt
[icmet04:393173] *** An error occurred in MPI_Recv
[icmet04:393173] *** reported by process [2566193153,2]
[icmet04:393173] *** on communicator MPI_COMM_WORLD
[icmet04:393173] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393173] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393173] ***    and potentially your MPI job)
[icmet04:393167] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[icmet04:393167] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages


mpirun -np 4 ./main -d -g 2
Number of MPI processes         4
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-4-2.txt
[icmet04:393200] *** An error occurred in MPI_Recv
[icmet04:393200] *** reported by process [2563964929,3]
[icmet04:393200] *** on communicator MPI_COMM_WORLD
[icmet04:393200] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393200] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393200] ***    and potentially your MPI job)
[icmet04:393193] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[icmet04:393193] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages


mpirun -np 1 ./main -d -g 3
Number of MPI processes         1
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-1-3.txt
Time for Parallel Training: 0.347954 seconds
Precision on validation set for parallel training =   0.7853333353996277
Precision on testing set for parallel training =   0.7652999758720398

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-3.mat
Loading from file ./cpu_output/seq_nn-b0-3.mat
Loading from file ./cpu_output/seq_nn-W1-3.mat
Loading from file ./cpu_output/seq_nn-b1-3.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-1-3.txt
Max norm of diff b/w seq and par: W[0]: 3.46339e-08, b[0]: 4.92726e-07
l2  norm of diff b/w seq and par: W[0]: 5.41946e-08, b[0]: 2.75113e-07
Max norm of diff b/w seq and par: W[1]: 6.51266e-08, b[1]: 3.99422e-07
l2  norm of diff b/w seq and par: W[1]: 8.18991e-08, b[1]: 3.56919e-07


mpirun -np 2 ./main -d -g 3
Number of MPI processes         2
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-2-3.txt
[icmet04:393243] *** An error occurred in MPI_Recv
[icmet04:393243] *** reported by process [1731133441,1]
[icmet04:393243] *** on communicator MPI_COMM_WORLD
[icmet04:393243] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393243] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393243] ***    and potentially your MPI job)


mpirun -np 3 ./main -d -g 3
Number of MPI processes         3
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-3-3.txt
[icmet04:393266] *** An error occurred in MPI_Recv
[icmet04:393266] *** reported by process [1729363969,1]
[icmet04:393266] *** on communicator MPI_COMM_WORLD
[icmet04:393266] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393266] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393266] ***    and potentially your MPI job)
[icmet04:393261] 1 more process has sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[icmet04:393261] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages


mpirun -np 4 ./main -d -g 3
Number of MPI processes         4
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-4-3.txt
[icmet04:393293] *** An error occurred in MPI_Recv
[icmet04:393293] *** reported by process [1736310785,2]
[icmet04:393293] *** on communicator MPI_COMM_WORLD
[icmet04:393293] *** MPI_ERR_BUFFER: invalid buffer pointer
[icmet04:393293] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[icmet04:393293] ***    and potentially your MPI job)
[icmet04:393287] 2 more processes have sent help message help-mpi-errors.txt / mpi_errors_are_fatal
[icmet04:393287] Set MCA parameter "orte_base_help_aggregate" to 0 to see all help / error messages

*** Summary ***


*** Grading mode 4 ***

main -g 4
Number of MPI processes         4
Number of CUDA devices          4

Entering GEMM Benchmarking mode! Stand by.

Starting GEMM 1: M = 8000; N = 10000; K = 7840
GEMM matched with reference successfully! Rel diff = 5.03676e-08
Time for reference GEMM implementation: 0.489563 seconds
Time for my GEMM implementation: 5.75567 seconds
Completed GEMM 1

Starting GEMM 2: M = 8000; N = 1000; K = 10000
GEMM matched with reference successfully! Rel diff = 5.08913e-08
Time for reference GEMM implementation: 0.0630253 seconds
Time for my GEMM implementation: 0.697867 seconds
Completed GEMM 2

Starting GEMM 3: M = 8000; N = 100; K = 10000
GEMM matched with reference successfully! Rel diff = 1.07542e-06
Time for reference GEMM implementation: 0.00815207 seconds
Time for my GEMM implementation: 0.0858512 seconds
Completed GEMM 3

*** Tests are complete ***
