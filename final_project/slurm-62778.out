Starting at Tue Jun 13 02:37:18 AM UTC 2023
Current working directory is /home/leonkl/cme-213/final_project
The master node of this job is: icmet01
Number of compute nodes: 1
Compute node names: icmet01
Using 4 tasks per node.
Number of CPUs on node: 4.
----------------


mpirun -np 1 ./main -d -g 1
Number of MPI processes         1
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-1-1.txt
Time for Parallel Training: 9.45866 seconds
Precision on validation set for parallel training =   0.9104999899864197
Precision on testing set for parallel training =   0.8920000195503235

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-1.mat
Loading from file ./cpu_output/seq_nn-b0-1.mat
Loading from file ./cpu_output/seq_nn-W1-1.mat
Loading from file ./cpu_output/seq_nn-b1-1.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-1-1.txt
Max norm of diff b/w seq and par: W[0]: 1.24679e-07, b[0]: 6.72605e-07
l2  norm of diff b/w seq and par: W[0]: 1.51362e-07, b[0]: 5.1166e-07
Max norm of diff b/w seq and par: W[1]: 1.62851e-07, b[1]: 9.71734e-07
l2  norm of diff b/w seq and par: W[1]: 1.91931e-07, b[1]: 9.79369e-07


mpirun -np 2 ./main -d -g 1
Number of MPI processes         2
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-2-1.txt
Time for Parallel Training: 10.5695 seconds
Precision on validation set for parallel training =   0.9104999899864197
Precision on testing set for parallel training =   0.8920000195503235

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-1.mat
Loading from file ./cpu_output/seq_nn-b0-1.mat
Loading from file ./cpu_output/seq_nn-W1-1.mat
Loading from file ./cpu_output/seq_nn-b1-1.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-2-1.txt
Max norm of diff b/w seq and par: W[0]: 1.23276e-07, b[0]: 8.4556e-07
l2  norm of diff b/w seq and par: W[0]: 1.47945e-07, b[0]: 5.3834e-07
Max norm of diff b/w seq and par: W[1]: 1.40405e-07, b[1]: 1.17996e-06
l2  norm of diff b/w seq and par: W[1]: 1.42079e-07, b[1]: 1.06327e-06


mpirun -np 3 ./main -d -g 1
Number of MPI processes         3
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-3-1.txt
Time for Parallel Training: 15.7205 seconds
Precision on validation set for parallel training =   0.9104999899864197
Precision on testing set for parallel training =   0.8920000195503235

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-1.mat
Loading from file ./cpu_output/seq_nn-b0-1.mat
Loading from file ./cpu_output/seq_nn-W1-1.mat
Loading from file ./cpu_output/seq_nn-b1-1.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-3-1.txt
Max norm of diff b/w seq and par: W[0]: 1.2146e-07, b[0]: 7.68691e-07
l2  norm of diff b/w seq and par: W[0]: 1.46847e-07, b[0]: 5.42302e-07
Max norm of diff b/w seq and par: W[1]: 1.36468e-07, b[1]: 6.94096e-07
l2  norm of diff b/w seq and par: W[1]: 1.37044e-07, b[1]: 9.01223e-07


mpirun -np 4 ./main -d -g 1
Number of MPI processes         4
Number of CUDA devices          4
Grading mode on; grading mode   1
Number of neurons            1000
Number of epochs               40
Batch size                    800
Regularization      9.9999997e-05
Learning rate       0.00050000002
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-4-1.txt
Time for Parallel Training: 13.3819 seconds
Precision on validation set for parallel training =   0.9104999899864197
Precision on testing set for parallel training =   0.8920000195503235

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-1.mat
Loading from file ./cpu_output/seq_nn-b0-1.mat
Loading from file ./cpu_output/seq_nn-W1-1.mat
Loading from file ./cpu_output/seq_nn-b1-1.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-4-1.txt
Max norm of diff b/w seq and par: W[0]: 1.21039e-07, b[0]: 6.53388e-07
l2  norm of diff b/w seq and par: W[0]: 1.45882e-07, b[0]: 5.30939e-07
Max norm of diff b/w seq and par: W[1]: 1.38712e-07, b[1]: 1.04114e-06
l2  norm of diff b/w seq and par: W[1]: 1.41839e-07, b[1]: 1.00635e-06


mpirun -np 1 ./main -d -g 2
Number of MPI processes         1
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-1-2.txt
Time for Parallel Training: 2.44073 seconds
Precision on validation set for parallel training =   0.8845000267028809
Precision on testing set for parallel training =   0.8647999763488770

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-2.mat
Loading from file ./cpu_output/seq_nn-b0-2.mat
Loading from file ./cpu_output/seq_nn-W1-2.mat
Loading from file ./cpu_output/seq_nn-b1-2.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-1-2.txt
Max norm of diff b/w seq and par: W[0]: 9.32387e-08, b[0]: 7.19345e-07
l2  norm of diff b/w seq and par: W[0]: 1.09187e-07, b[0]: 4.19014e-07
Max norm of diff b/w seq and par: W[1]: 1.27186e-07, b[1]: 6.3164e-07
l2  norm of diff b/w seq and par: W[1]: 1.55776e-07, b[1]: 4.95631e-07


mpirun -np 2 ./main -d -g 2
Number of MPI processes         2
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-2-2.txt
Time for Parallel Training: 2.80969 seconds
Precision on validation set for parallel training =   0.8845000267028809
Precision on testing set for parallel training =   0.8647999763488770

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-2.mat
Loading from file ./cpu_output/seq_nn-b0-2.mat
Loading from file ./cpu_output/seq_nn-W1-2.mat
Loading from file ./cpu_output/seq_nn-b1-2.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-2-2.txt
Max norm of diff b/w seq and par: W[0]: 9.45522e-08, b[0]: 5.652e-07
l2  norm of diff b/w seq and par: W[0]: 1.06598e-07, b[0]: 4.13527e-07
Max norm of diff b/w seq and par: W[1]: 1.09254e-07, b[1]: 7.72004e-07
l2  norm of diff b/w seq and par: W[1]: 1.14506e-07, b[1]: 5.59025e-07


mpirun -np 3 ./main -d -g 2
Number of MPI processes         3
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-3-2.txt
Time for Parallel Training: 3.45531 seconds
Precision on validation set for parallel training =   0.8845000267028809
Precision on testing set for parallel training =   0.8647999763488770

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-2.mat
Loading from file ./cpu_output/seq_nn-b0-2.mat
Loading from file ./cpu_output/seq_nn-W1-2.mat
Loading from file ./cpu_output/seq_nn-b1-2.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-3-2.txt
Max norm of diff b/w seq and par: W[0]: 9.2708e-08, b[0]: 5.652e-07
l2  norm of diff b/w seq and par: W[0]: 1.07721e-07, b[0]: 4.04402e-07
Max norm of diff b/w seq and par: W[1]: 1.03988e-07, b[1]: 4.21093e-07
l2  norm of diff b/w seq and par: W[1]: 1.13033e-07, b[1]: 3.6957e-07


mpirun -np 4 ./main -d -g 2
Number of MPI processes         4
Number of CUDA devices          4
Grading mode on; grading mode   2
Number of neurons            1000
Number of epochs               10
Batch size                    800
Regularization      9.9999997e-05
Learning rate               0.001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-4-2.txt
Time for Parallel Training: 3.60154 seconds
Precision on validation set for parallel training =   0.8845000267028809
Precision on testing set for parallel training =   0.8647999763488770

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-2.mat
Loading from file ./cpu_output/seq_nn-b0-2.mat
Loading from file ./cpu_output/seq_nn-W1-2.mat
Loading from file ./cpu_output/seq_nn-b1-2.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-4-2.txt
Max norm of diff b/w seq and par: W[0]: 9.30893e-08, b[0]: 5.13818e-07
l2  norm of diff b/w seq and par: W[0]: 1.07317e-07, b[0]: 4.11442e-07
Max norm of diff b/w seq and par: W[1]: 1.03769e-07, b[1]: 4.21093e-07
l2  norm of diff b/w seq and par: W[1]: 1.12398e-07, b[1]: 3.75645e-07


mpirun -np 1 ./main -d -g 3
Number of MPI processes         1
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-1-3.txt
Time for Parallel Training: 0.341289 seconds
Precision on validation set for parallel training =   0.7853333353996277
Precision on testing set for parallel training =   0.7652999758720398

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-3.mat
Loading from file ./cpu_output/seq_nn-b0-3.mat
Loading from file ./cpu_output/seq_nn-W1-3.mat
Loading from file ./cpu_output/seq_nn-b1-3.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-1-3.txt
Max norm of diff b/w seq and par: W[0]: 3.46339e-08, b[0]: 4.92726e-07
l2  norm of diff b/w seq and par: W[0]: 5.41946e-08, b[0]: 2.75113e-07
Max norm of diff b/w seq and par: W[1]: 6.51266e-08, b[1]: 3.99422e-07
l2  norm of diff b/w seq and par: W[1]: 8.18991e-08, b[1]: 3.56919e-07


mpirun -np 2 ./main -d -g 3
Number of MPI processes         2
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-2-3.txt
Time for Parallel Training: 0.504234 seconds
Precision on validation set for parallel training =   0.7853333353996277
Precision on testing set for parallel training =   0.7652999758720398

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-3.mat
Loading from file ./cpu_output/seq_nn-b0-3.mat
Loading from file ./cpu_output/seq_nn-W1-3.mat
Loading from file ./cpu_output/seq_nn-b1-3.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-2-3.txt
Max norm of diff b/w seq and par: W[0]: 3.76041e-08, b[0]: 4.92726e-07
l2  norm of diff b/w seq and par: W[0]: 5.33141e-08, b[0]: 2.76107e-07
Max norm of diff b/w seq and par: W[1]: 4.5665e-08, b[1]: 4.39364e-07
l2  norm of diff b/w seq and par: W[1]: 6.23873e-08, b[1]: 3.35911e-07


mpirun -np 3 ./main -d -g 3
Number of MPI processes         3
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-3-3.txt
Time for Parallel Training: 0.60101 seconds
Precision on validation set for parallel training =   0.7853333353996277
Precision on testing set for parallel training =   0.7652999758720398

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-3.mat
Loading from file ./cpu_output/seq_nn-b0-3.mat
Loading from file ./cpu_output/seq_nn-W1-3.mat
Loading from file ./cpu_output/seq_nn-b1-3.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-3-3.txt
Max norm of diff b/w seq and par: W[0]: 3.69773e-08, b[0]: 4.92726e-07
l2  norm of diff b/w seq and par: W[0]: 5.45502e-08, b[0]: 2.81853e-07
Max norm of diff b/w seq and par: W[1]: 4.61694e-08, b[1]: 6.39075e-07
l2  norm of diff b/w seq and par: W[1]: 6.70547e-08, b[1]: 5.75412e-07


mpirun -np 4 ./main -d -g 3
Number of MPI processes         4
Number of CUDA devices          4
Grading mode on; grading mode   3
Number of neurons            1000
Number of epochs                1
Batch size                    800
Regularization      9.9999997e-05
Learning rate        0.0020000001
The sequential code is not run
The debug option is on
The output directory is Outputs
The CPU results are loaded from ./cpu_output
Loading training data
Training data information:
Size of x_train, N =  60000
Size of label_train = 60000
Loading testing data

Start Parallel Training
The error in the GPU calculation during training is saved to Outputs/CpuGpuDiff-4-3.txt
Time for Parallel Training: 0.659187 seconds
Precision on validation set for parallel training =   0.7853333353996277
Precision on testing set for parallel training =   0.7652999758720398

Checking for correctness...
Loading from file ./cpu_output/seq_nn-W0-3.mat
Loading from file ./cpu_output/seq_nn-b0-3.mat
Loading from file ./cpu_output/seq_nn-W1-3.mat
Loading from file ./cpu_output/seq_nn-b1-3.mat

The error in the GPU DNN at the completion of training is saved to Outputs/NNErrors-4-3.txt
Max norm of diff b/w seq and par: W[0]: 3.66788e-08, b[0]: 4.05775e-07
l2  norm of diff b/w seq and par: W[0]: 5.22804e-08, b[0]: 2.77595e-07
Max norm of diff b/w seq and par: W[1]: 4.01571e-08, b[1]: 4.79306e-07
l2  norm of diff b/w seq and par: W[1]: 5.62332e-08, b[1]: 4.37842e-07

*** Summary ***


*** Grading mode 4 ***

main -g 4
Number of MPI processes         4
Number of CUDA devices          4

Entering GEMM Benchmarking mode! Stand by.

Starting GEMM 1: M = 8000; N = 10000; K = 7840
GEMM matched with reference successfully! Rel diff = 5.03676e-08
Time for reference GEMM implementation: 0.489536 seconds
Time for my GEMM implementation: 5.76285 seconds
Completed GEMM 1

Starting GEMM 2: M = 8000; N = 1000; K = 10000
GEMM matched with reference successfully! Rel diff = 5.08913e-08
Time for reference GEMM implementation: 0.0635895 seconds
Time for my GEMM implementation: 0.69855 seconds
Completed GEMM 2

Starting GEMM 3: M = 8000; N = 100; K = 10000
GEMM matched with reference successfully! Rel diff = 1.07542e-06
Time for reference GEMM implementation: 0.00815363 seconds
Time for my GEMM implementation: 0.0857768 seconds
Completed GEMM 3

*** Tests are complete ***
